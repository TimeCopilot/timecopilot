{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Mode\n",
    "\n",
    "TimeCopilot ships with a fully interactive terminal experience that lets you select models, configure API keys, load data, and ask follow-up questions — all from a single session. This guide walks through every step of the interactive flow, from first launch to ongoing conversations with your data.\n",
    "\n",
    "> **Note:** Interactive mode runs in your terminal, not inside a notebook. The code blocks below show the commands and expected output you'll see in your shell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching interactive mode\n",
    "\n",
    "Start an interactive session by running the CLI with no subcommand:\n",
    "\n",
    "```bash\n",
    "timecopilot\n",
    "```\n",
    "\n",
    "You can also pass a specific LLM at launch to skip the model picker entirely:\n",
    "\n",
    "```bash\n",
    "timecopilot --llm anthropic:claude-sonnet-4-5-20250929\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-time onboarding\n",
    "\n",
    "When no saved configuration is found, TimeCopilot walks you through a short setup flow.\n",
    "\n",
    "### 1. LLM selection prompt\n",
    "\n",
    "The first thing you see is a yes/no question:\n",
    "\n",
    "```\n",
    "Would you like to select an LLM? (yes/no)\n",
    "```\n",
    "\n",
    "- **yes** (or press Enter) — opens the two-step model picker described below.\n",
    "- **no** — keeps the default model (`openai:gpt-4o-mini`) and moves straight to the API key step.\n",
    "\n",
    "### 2. Provider picker\n",
    "\n",
    "If you chose yes, a table of available providers is displayed:\n",
    "\n",
    "```\n",
    "         Select a provider\n",
    "┏━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━┓\n",
    "┃ #  ┃ Provider      ┃ Models    ┃\n",
    "┡━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━┩\n",
    "│ 1  │ openai        │ 72 models │\n",
    "│ 2  │ anthropic     │ 19 models │\n",
    "│ 3  │ google-gla    │ 9 models  │\n",
    "│ …  │ …             │ …         │\n",
    "└────┴───────────────┴───────────┘\n",
    "Select a provider:\n",
    "```\n",
    "\n",
    "Enter a number, a provider name, or type `back` to return to the previous step.\n",
    "\n",
    "### 3. Model picker\n",
    "\n",
    "After selecting a provider you see its models listed in a similar table. Pick one by number or name, or type `back` to return to the provider list.\n",
    "\n",
    "### 4. API key\n",
    "\n",
    "TimeCopilot checks whether the required API key environment variable is set for the selected provider (e.g. `OPENAI_API_KEY` for OpenAI, `ANTHROPIC_API_KEY` for Anthropic). If it is missing you are prompted to enter it:\n",
    "\n",
    "```\n",
    "Enter your OPENAI_API_KEY:\n",
    "```\n",
    "\n",
    "The key is saved to `timecopilot/.env` so you only need to enter it once. Type `back` to return to model selection instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning users\n",
    "\n",
    "When a valid saved configuration already exists, TimeCopilot greets you with a short welcome-back message showing the current model and a command reference table. No onboarding steps are repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The chat loop\n",
    "\n",
    "Once setup is complete, you land in the main prompt:\n",
    "\n",
    "```\n",
    "TimeCopilot:\n",
    "```\n",
    "\n",
    "From here you can load data, ask questions, and issue commands.\n",
    "\n",
    "### Loading data\n",
    "\n",
    "Provide a file path or URL to kick off an analysis:\n",
    "\n",
    "```\n",
    "TimeCopilot: forecast /path/to/sales.csv\n",
    "```\n",
    "\n",
    "TimeCopilot accepts `.csv` and `.parquet` files as well as HTTP/S3 URLs. After loading, it selects the best forecasting model, generates predictions, and reports the results — including any anomalies it detects.\n",
    "\n",
    "### Follow-up questions\n",
    "\n",
    "After the initial analysis you can ask natural-language follow-up questions in the same session:\n",
    "\n",
    "```\n",
    "TimeCopilot: Why does the forecast spike in December?\n",
    "TimeCopilot: Show me a plot of the forecast vs actual values\n",
    "TimeCopilot: Compare Chronos and TimesFM for this dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commands\n",
    "\n",
    "The following commands are available at the `TimeCopilot:` prompt:\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `help` or `?` | Show the welcome message with examples and command reference |\n",
    "| `llm` | Switch to a different model (opens the provider → model picker) |\n",
    "| `back` | Go back to the previous step during onboarding or model selection |\n",
    "| `exit`, `quit`, or `bye` | Exit TimeCopilot |\n",
    "\n",
    "> **Tip — Switching models mid-session:** Type `llm` at any point to open the model picker and switch providers or models without restarting TimeCopilot. Your new selection is saved for future sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration persistence\n",
    "\n",
    "All configuration is stored in the `timecopilot/.env` file inside your project directory:\n",
    "\n",
    "- **Selected model** — saved as `TIMECOPILOT_MODEL`\n",
    "- **API keys** — saved under their standard environment variable names (e.g. `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`)\n",
    "\n",
    "Delete this file to reset your configuration and trigger the onboarding flow again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
